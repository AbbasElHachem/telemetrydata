{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy import spatial\n",
    "path_to_dfs = (r'/home/abbas/Documents/2020_03_03_SJE/2019_05_03_fish_dfs/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = glob.glob(path_to_dfs)\n",
    "\n",
    "assert len(dfs) > 0, 'no files found'\n",
    "#assert dfs[0].endswith('.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 100 6\n"
     ]
    }
   ],
   "source": [
    "len(dfs)\n",
    "\n",
    "\n",
    "dfs_barbel = [df for df in dfs if 'barbel' in df]\n",
    "dfs_grayling = [df for df in dfs if 'grayling' in df]\n",
    "dfs_chub = [df for df in dfs if 'chub' in df]\n",
    "print(len(dfs_barbel), len(dfs_grayling), len(dfs_chub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_max_gradient_direct(fish_flow_file,\n",
    "                             flow_cat,\n",
    "                             fish_nbr,\n",
    "                             distance_thr=2):\n",
    "    '''\n",
    "    a function used to calculate between every position\n",
    "    and closest 4 positions the difference in the\n",
    "    depth gradient and flow velocity\n",
    "    find the maximum difference and add it to the df\n",
    "\n",
    "    https://stackoverflow.com/questions/53028514/\n",
    "    calculate-distance-from-one-point-to-all-others\n",
    "    '''\n",
    "    fish_flow_df = pd.read_csv(fish_flow_file, sep=',', index_col=0,\n",
    "                               parse_dates=True, engine='c')\n",
    "\n",
    "#     fish_flow_df = fish_flow_df.head(10)\n",
    "\n",
    "    flow_val = flow_cat[-2:]\n",
    "    \n",
    "    depth_var = 'depth_%s' % flow_val\n",
    "    flow_var = 'velM_%s' % flow_val\n",
    "    print(flow_val, depth_var, flow_var)\n",
    "    #print('calculting for', fish_flow_file)\n",
    "\n",
    "    x_grid_between = fish_flow_df.loc[:, 'X_of_grid_node']\n",
    "    y_grid_between = fish_flow_df.loc[:, 'Y_of_grid_node']\n",
    "\n",
    "    take_idxs = np.ones(x_grid_between.size, dtype=bool)\n",
    "    for i in range(x_grid_between.size):\n",
    "\n",
    "        if not take_idxs[i]:\n",
    "            continue\n",
    "\n",
    "        x_dists = (x_grid_between[i] - x_grid_between)**2\n",
    "        y_dists = (y_grid_between[i] - y_grid_between)**2\n",
    "\n",
    "        dists = (x_dists + y_dists)**0.5\n",
    "\n",
    "        equal_dist_idxs = np.where((dists < 5e-1))[0]\n",
    "\n",
    "        take_idxs[equal_dist_idxs[1:]] = False\n",
    "\n",
    "    x_grid_between_unique_series = x_grid_between[take_idxs]\n",
    "    y_grid_between_unique_series = y_grid_between[take_idxs]\n",
    "\n",
    "    try:\n",
    "        print('getting data')\n",
    "        for ix in fish_flow_df.index:\n",
    "            #print(ix)\n",
    "\n",
    "            depth_point0 = fish_flow_df.loc[ix, depth_var]\n",
    "            flow_vel_point0 = fish_flow_df.loc[ix, flow_var]\n",
    "\n",
    "#             ix_before = ix - pd.Timedelta(minutes=timedelta)\n",
    "#             ix_after = ix + pd.Timedelta(minutes=timedelta)\n",
    "\n",
    "#             df_between = fish_flow_df.loc[ix_before:ix_after, :]\n",
    "\n",
    "            #==================================================================\n",
    "            x0 = fish_flow_df.loc[ix, 'X_of_grid_node']\n",
    "            y0 = fish_flow_df.loc[ix, 'Y_of_grid_node']\n",
    "\n",
    "            x_dists = (x0 - x_grid_between_unique_series.values)**2\n",
    "            y_dists = (y0 - y_grid_between_unique_series.values)**2\n",
    "\n",
    "            dists = (x_dists + y_dists)**0.5\n",
    "\n",
    "            x_grid_between_unique_series_near = x_grid_between_unique_series[\n",
    "                (0 < dists) & (dists <= distance_thr)]\n",
    "            y_grid_between_unique_series_near = y_grid_between_unique_series[\n",
    "                (0 < dists) & (dists <= distance_thr)]\n",
    "\n",
    "            dists_below_thr = dists[(0 < dists) & (dists <= distance_thr)]\n",
    "\n",
    "            if dists_below_thr.size > 0:\n",
    "\n",
    "                nrsts_idxs = np.argsort(dists_below_thr)[:5]\n",
    "                x_nebors = x_grid_between_unique_series_near[nrsts_idxs]\n",
    "                y_nebors = y_grid_between_unique_series_near[nrsts_idxs]\n",
    "\n",
    "                #==============================================================\n",
    "#                 if (x0 in x_nebors) and (y0 in y_nebors):\n",
    "#                     x_nebors = list(x_nebors.values)\n",
    "#                     y_nebors = list(y_nebors.values)\n",
    "#                     i = 0  # loop counter\n",
    "#                     length = len(x_nebors)  # list length\n",
    "#                     while (i < length):\n",
    "#                         if (x_nebors[i] == x0) and (y_nebors[i] == y0):\n",
    "#                             print('removing x0, y0 from points')\n",
    "#                             x_nebors.remove(x_nebors[i])\n",
    "#                             y_nebors.remove(y_nebors[i])\n",
    "#                             # as an element is removed\n",
    "#                             # so decrease the length by 1\n",
    "#                             length = length - 1\n",
    "#                             # run loop again to check element\n",
    "#                             # at same index, when item removed\n",
    "#                             # next item will shift to the left\n",
    "#                             continue\n",
    "#                         i = i + 1\n",
    "\n",
    "                x_nebors_arr_noX0 = np.array(x_nebors)\n",
    "                y_nebors_arr_noY0 = np.array(y_nebors)\n",
    "\n",
    "#                 plt.ioff()\n",
    "#                 plt.scatter(x_nebors, y_nebors, c='g', alpha=0.75)\n",
    "#                 plt.scatter(x_fish, y_fish, c='orange', alpha=0.5)\n",
    "#                 plt.scatter(x0, y0, c='r', alpha=0.5)\n",
    "\n",
    "                diff_in_grds_lst, diff_in_vel_lst = [], []\n",
    "                for xnear, ynear in zip(x_nebors_arr_noX0, y_nebors_arr_noY0):\n",
    "                    if xnear == x0 and ynear == y0:\n",
    "                        print('Error Same grid point')\n",
    "                        raise Exception\n",
    "\n",
    "                    df_xynear = fish_flow_df[\n",
    "                        (fish_flow_df.loc[:, 'X_of_grid_node'] == xnear) &\n",
    "                        (fish_flow_df.loc[:, 'Y_of_grid_node'] == ynear)]\n",
    "\n",
    "                    point_i_depth = df_xynear.loc[:, depth_var].values\n",
    "                    point_i_flow_mag = df_xynear.loc[:, flow_var].values\n",
    "\n",
    "                    diff_in_grds_lst.append(\n",
    "                        np.abs(depth_point0 - point_i_depth))\n",
    "                    diff_in_vel_lst.append(\n",
    "                        np.abs(flow_vel_point0 - point_i_flow_mag))\n",
    "\n",
    "                diff_in_grds_lst_unique = [\n",
    "                    np.unique(arr) for arr in diff_in_grds_lst]\n",
    "                diff_in_vel_lst_unique = [\n",
    "                    np.unique(arr) for arr in diff_in_vel_lst]\n",
    "\n",
    "                (_, depth_point_id) = (\n",
    "                    np.max(diff_in_grds_lst_unique),\n",
    "                    np.argmax(diff_in_grds_lst_unique))\n",
    "\n",
    "                (_, vel_point_id) = (\n",
    "                    np.max(diff_in_vel_lst_unique),\n",
    "                    np.argmax(diff_in_vel_lst_unique))\n",
    "\n",
    "                (x_d, y_d) = (x_nebors[depth_point_id],\n",
    "                              y_nebors[depth_point_id])\n",
    "                (x_v, y_v) = (x_nebors[vel_point_id],\n",
    "                              y_nebors[vel_point_id])\n",
    "                assert not (x_d == x0 and y_d ==\n",
    "                            y0), 'Error gradient same point'\n",
    "                assert not (x_v == x0 and y_v ==\n",
    "                            y0), 'Error gradient same point'\n",
    "\n",
    "#                 plt.scatter(x_d, y_d, c='darkblue')\n",
    "#                 plt.scatter(x_v, y_v, c='orange')\n",
    "\n",
    "                direction_max_depth_grd = np.math.degrees(\n",
    "                    np.math.atan2((y_d - y0), (x_d - x0)))\n",
    "                direction_max_vel_grd = np.math.degrees(\n",
    "                    np.math.atan2((y_v - y0), (x_v - x0)))\n",
    "\n",
    "#                 fish_flow_df.loc[ix,\n",
    "#                                  'X_coords_grid_with_max_%s_gradient_diff'\n",
    "#                                  % depth_var] = x_d\n",
    "#\n",
    "#                 fish_flow_df.loc[ix,\n",
    "#                                  'Y_coords_grid_with_max_%s_gradient_diff'\n",
    "#                                  % depth_var] = y_d\n",
    "#\n",
    "#                 fish_flow_df.loc[ix,\n",
    "#                                  'X_coords_grid_with_max_%s_gradient_diff'\n",
    "#                                  % flow_var] = x_v\n",
    "#\n",
    "#                 fish_flow_df.loc[ix,\n",
    "#                                  'Y_coords_grid_with_max_%s_gradient_diff'\n",
    "#                                  % flow_var] = y_v\n",
    "\n",
    "                fish_flow_df.loc[ix,\n",
    "                                 'Direction_max_%s_gradient_compared_to_grid_point_and_x_axis'\n",
    "                                 % depth_var] = direction_max_depth_grd\n",
    "                fish_flow_df.loc[ix,\n",
    "                                 'Direction_max_%s_gradient_compared_to_grid_point_and_x_axis'\n",
    "                                 % flow_var] = direction_max_vel_grd\n",
    "\n",
    "                diff_fish_max_depth_grd = np.mod(\n",
    "                    # 'fish_angle'\n",
    "                    fish_flow_df.loc[ix, 'Fish_swim_direction_compared_to_x_axis'] -\n",
    "                    direction_max_depth_grd + 180, 360) - 180\n",
    "\n",
    "                diff_fish_max_vel_grd = np.mod(\n",
    "                    fish_flow_df.loc[ix, 'Fish_swim_direction_compared_to_x_axis'] -\n",
    "                    direction_max_vel_grd + 180, 360) - 180\n",
    "\n",
    "                fish_flow_df.loc[ix,\n",
    "                                 'Angle_between_swim_and_max_%s_gradient_direction'\n",
    "                                 % depth_var] = diff_fish_max_depth_grd\n",
    "                fish_flow_df.loc[ix,\n",
    "                                 'Angle_between_swim_and_max_%s_gradient_direction'\n",
    "                                 % flow_var] = diff_fish_max_vel_grd\n",
    "            else:\n",
    "                #print('Assigning Nans because no nearest neighbour found')\n",
    "\n",
    "#                 fish_flow_df.loc[ix,\n",
    "#                                  'X_coords_grid_with_max_%s_gradient_diff'\n",
    "#                                  % depth_var] = np.nan\n",
    "#\n",
    "#                 fish_flow_df.loc[ix,\n",
    "#                                  'Y_coords_grid_with_max_%s_gradient_diff'\n",
    "#                                  % depth_var] = np.nan\n",
    "#\n",
    "#                 fish_flow_df.loc[ix,\n",
    "#                                  'X_coords_grid_with_max_%s_gradient_diff'\n",
    "#                                  % flow_var] = np.nan\n",
    "#\n",
    "#                 fish_flow_df.loc[ix,\n",
    "#                                  'Y_coords_grid_with_max_%s_gradient_diff'\n",
    "#                                  % flow_var] = np.nan\n",
    "\n",
    "                fish_flow_df.loc[ix,\n",
    "                                 'Direction_max_%s_gradient_compared_to_grid_point_and_x_axis'\n",
    "                                 % depth_var] = np.nan\n",
    "                fish_flow_df.loc[ix,\n",
    "                                 'Direction_max_%s_gradient_compared_to_grid_point_and_x_axis'\n",
    "                                 % flow_var] = np.nan\n",
    "\n",
    "                fish_flow_df.loc[ix,\n",
    "                                 'Angle_between_swim_and_max_%s_gradient_direction'\n",
    "                                 % depth_var] = np.nan\n",
    "                fish_flow_df.loc[ix,\n",
    "                                 'Angle_between_swim_and_max_%s_gradient_direction'\n",
    "                                 % flow_var] = np.nan\n",
    "    except Exception as msg:\n",
    "        print(msg)\n",
    "    print('saving df')\n",
    "#     fish_flow_df.rename(\n",
    "#         columns={'Velocity': 'Fish_swim_velocity_m_per_s',\n",
    "#                  'x_fish': 'Fish_x_coord',\n",
    "#                  'y_fish': 'Fish_y_coord',\n",
    "#                  'index_of_grid_node': 'Index_of_grid_node',\n",
    "#                  'fish_angle': 'Fish_swim_direction_compared_to_x_axis',\n",
    "#                  'flow_angle': 'Flow_direction_compared_to_x_axis',\n",
    "#                  'angle_diff': 'Angle_between_swim_and_flow_direction'},\n",
    "#         inplace=True)\n",
    "#     deltax = fish_flow_df.Fish_x_coord.diff()\n",
    "#     deltay = fish_flow_df.Fish_x_coord.diff()\n",
    "#     fish_flow_df['Time'] = fish_flow_df.index\n",
    "#     fish_flow_df['Time_difference_in_s'] = np.round(\n",
    "#         fish_flow_df.Time.diff() / pd.Timedelta('1s'), 1)\n",
    "#     fish_flow_df['Traveled_distance_in_m'] = calculate_distance_2_points(deltax,\n",
    "#                                                                          deltay)\n",
    "#         fish_flow_df_final.drop('Time', axis=1, inplace=True)\n",
    "\n",
    "    cols_new = ['Longitude', 'Latitude', 'Fish_x_coord',\n",
    "                'Fish_y_coord', 'Time_difference_in_s',\n",
    "                'Traveled_distance_in_m',\n",
    "                'Fish_swim_velocity_m_per_s', 'HPE', 'RMSE',\n",
    "                'Flow_Cat', 'Index_of_grid_node',\n",
    "                'X_of_grid_node', 'Y_of_grid_node', 'Z_of_grid_node',\n",
    "                'depth_%s' % flow_val, 'velX_%s' % flow_val,\n",
    "                'velY_%s' % flow_val, 'velM_%s' % flow_val,\n",
    "                'Fish_swim_direction_compared_to_x_axis',\n",
    "                'Flow_direction_compared_to_x_axis',\n",
    "                'Angle_between_swim_and_flow_direction',\n",
    "                #                 'X_coords_grid_with_max_%s_gradient_diff'\n",
    "                #                 % depth_var,\n",
    "                #                 'Y_coords_grid_with_max_%s_gradient_diff'\n",
    "                #                 % depth_var,\n",
    "                #                 'X_coords_grid_with_max_%s_gradient_diff'\n",
    "                #                 % flow_var,\n",
    "                #                 'Y_coords_grid_with_max_%s_gradient_diff'\n",
    "                #                 % flow_var,\n",
    "                'Direction_max_%s_gradient_compared_to_grid_point_and_x_axis'\n",
    "                % depth_var,\n",
    "                'Direction_max_%s_gradient_compared_to_grid_point_and_x_axis'\n",
    "                % flow_var,\n",
    "                'Angle_between_swim_and_max_%s_gradient_direction'\n",
    "                % depth_var,\n",
    "                'Angle_between_swim_and_max_%s_gradient_direction'\n",
    "                % flow_var,\n",
    "                'group']#,\n",
    "                #'Depth_Grad']\n",
    "    # change column names and save df\n",
    "    fish_flow_df_final = fish_flow_df[cols_new]\n",
    "\n",
    "    fish_flow_df_final.to_csv(\n",
    "        os.path.join(r'/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/',\n",
    "                     r'fish_%s_with_flow_data_%s_angles'\n",
    "                     r'_and_max_gradients_behavior_new.csv'\n",
    "                     % (fish_nbr, flow_cat)), float_format='%0.6f')  # , compression='gzip')\n",
    "    print('Done saving df')\n",
    "    return fish_flow_df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ++ 1_grayling_46913  *  cat_20\n",
      "20 depth_20 velM_20\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "99 ++ 1_grayling_46863  *  cat_20\n",
      "20 depth_20 velM_20\n",
      "getting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-274-8fcf030a8f8e>:181: RuntimeWarning: invalid value encountered in remainder\n",
      "  diff_fish_max_depth_grd = np.mod(\n",
      "<ipython-input-274-8fcf030a8f8e>:186: RuntimeWarning: invalid value encountered in remainder\n",
      "  diff_fish_max_vel_grd = np.mod(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "98 ++ 1_grayling_46865  *  cat_60\n",
      "60 depth_60 velM_60\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "97 ++ 1_grayling_46912  *  cat_40\n",
      "40 depth_40 velM_40\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "96 ++ 1_grayling_46868  *  cat_20\n",
      "20 depth_20 velM_20\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "95 ++ 1_grayling_46909  *  cat_20\n",
      "20 depth_20 velM_20\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "94 ++ 1_grayling_46904  *  cat_80\n",
      "80 depth_80 velM_80\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "93 ++ 1_grayling_46908  *  cat_40\n",
      "40 depth_40 velM_40\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "92 ++ 1_grayling_46905  *  cat_20\n",
      "20 depth_20 velM_20\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "91 ++ 1_grayling_46906  *  cat_30\n",
      "30 depth_30 velM_30\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "90 ++ 1_grayling_46872  *  cat_80\n",
      "80 depth_80 velM_80\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "89 ++ 1_grayling_46912  *  cat_60\n",
      "60 depth_60 velM_60\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "88 ++ 1_grayling_46911  *  cat_60\n",
      "60 depth_60 velM_60\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "87 ++ 1_grayling_46901  *  cat_60\n",
      "60 depth_60 velM_60\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "86 ++ 1_grayling_46901  *  cat_30\n",
      "30 depth_30 velM_30\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "85 ++ 1_grayling_46906  *  cat_40\n",
      "40 depth_40 velM_40\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "84 ++ 1_grayling_46902  *  cat_30\n",
      "30 depth_30 velM_30\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "83 ++ 1_grayling_46909  *  cat_40\n",
      "40 depth_40 velM_40\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "82 ++ 1_grayling_46903  *  cat_80\n",
      "80 depth_80 velM_80\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "81 ++ 1_grayling_46907  *  cat_20\n",
      "20 depth_20 velM_20\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "80 ++ 1_grayling_46905  *  cat_80\n",
      "80 depth_80 velM_80\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "79 ++ 1_grayling_46866  *  cat_80\n",
      "80 depth_80 velM_80\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "78 ++ 1_grayling_46904  *  cat_40\n",
      "40 depth_40 velM_40\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "77 ++ 1_grayling_46912  *  cat_50\n",
      "50 depth_50 velM_50\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "76 ++ 1_grayling_46914  *  cat_30\n",
      "30 depth_30 velM_30\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "75 ++ 1_grayling_46869  *  cat_60\n",
      "60 depth_60 velM_60\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "74 ++ 1_grayling_46903  *  cat_50\n",
      "50 depth_50 velM_50\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "73 ++ 1_grayling_46901  *  cat_40\n",
      "40 depth_40 velM_40\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "72 ++ 1_grayling_46864  *  cat_80\n",
      "80 depth_80 velM_80\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "71 ++ 1_grayling_46871  *  cat_10\n",
      "10 depth_10 velM_10\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "70 ++ 1_grayling_46914  *  cat_80\n",
      "80 depth_80 velM_80\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "69 ++ 1_grayling_46908  *  cat_80\n",
      "80 depth_80 velM_80\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "68 ++ 1_grayling_46874  *  cat_60\n",
      "60 depth_60 velM_60\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "67 ++ 1_grayling_46901  *  cat_20\n",
      "20 depth_20 velM_20\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "66 ++ 1_grayling_46871  *  cat_20\n",
      "20 depth_20 velM_20\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "65 ++ 1_grayling_46903  *  cat_40\n",
      "40 depth_40 velM_40\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "64 ++ 1_grayling_46872  *  cat_60\n",
      "60 depth_60 velM_60\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "63 ++ 1_grayling_46905  *  cat_40\n",
      "40 depth_40 velM_40\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "62 ++ 1_grayling_46906  *  cat_50\n",
      "50 depth_50 velM_50\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "61 ++ 1_grayling_46903  *  cat_60\n",
      "60 depth_60 velM_60\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "60 ++ 1_grayling_46913  *  cat_50\n",
      "50 depth_50 velM_50\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "59 ++ 1_grayling_46871  *  cat_60\n",
      "60 depth_60 velM_60\n",
      "getting data\n",
      "saving df\n",
      "Done saving df\n",
      "DONE WITH THIS ONE\n",
      "58 ++ 1_grayling_46863  *  cat_10\n",
      "10 depth_10 velM_10\n",
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46863_with_flow_data_cat_10_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46904  *  cat_60\n",
      "60 depth_60 velM_60\n",
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46904_with_flow_data_cat_60_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46905  *  cat_30\n",
      "30 depth_30 velM_30\n",
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46905_with_flow_data_cat_30_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46865  *  cat_80\n",
      "80 depth_80 velM_80\n",
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46865_with_flow_data_cat_80_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46904  *  cat_10\n",
      "10 depth_10 velM_10\n",
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46904_with_flow_data_cat_10_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46865  *  cat_50\n",
      "50 depth_50 velM_50\n",
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46865_with_flow_data_cat_50_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46869  *  cat_80\n",
      "80 depth_80 velM_80\n",
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46869_with_flow_data_cat_80_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46912  *  cat_30\n",
      "30 depth_30 velM_30\n",
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46912_with_flow_data_cat_30_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46909  *  cat_50\n",
      "50 depth_50 velM_50\n",
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46909_with_flow_data_cat_50_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46907  *  cat_80\n",
      "80 depth_80 velM_80\n",
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46907_with_flow_data_cat_80_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46906  *  cat_60\n",
      "60 depth_60 velM_60\n",
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46906_with_flow_data_cat_60_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46864  *  cat_50\n",
      "50 depth_50 velM_50\n",
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46864_with_flow_data_cat_50_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46913  *  cat_40\n",
      "40 depth_40 velM_40\n",
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46913_with_flow_data_cat_40_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46910  *  cat_60\n",
      "60 depth_60 velM_60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data\n",
      "saving df\n",
      "[Errno 2] No such file or directory: '/run/media/abbas/EL Hachem 2019/from_C/Desktop/Work_with_Matthias_Schneider/2020_05_03_data/fish_1_grayling_46910_with_flow_data_cat_60_angles_and_max_gradients_behavior_new.csv'\n",
      "58 ++ 1_grayling_46901  *  cat_80\n",
      "80 depth_80 velM_80\n",
      "getting data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-285-68a21538af38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcalc_max_gradient_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfish_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-274-8fcf030a8f8e>\u001b[0m in \u001b[0;36mcalc_max_gradient_direct\u001b[0;34m(fish_flow_file, flow_cat, fish_nbr, distance_thr)\u001b[0m\n\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                     df_xynear = fish_flow_df[\n\u001b[0m\u001b[1;32m    117\u001b[0m                         \u001b[0;34m(\u001b[0m\u001b[0mfish_flow_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X_of_grid_node'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mxnear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                         (fish_flow_df.loc[:, 'Y_of_grid_node'] == ynear)]\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2789\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2793\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2843\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2845\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   3407\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3408\u001b[0m         \"\"\"\n\u001b[0;32m-> 3409\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3410\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3392\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3394\u001b[0;31m         new_data = self._data.take(\n\u001b[0m\u001b[1;32m   3395\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3396\u001b[0m         )\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m         return self.reindex_indexer(\n\u001b[0m\u001b[1;32m   1394\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m         )\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m             new_blocks = [\n\u001b[0m\u001b[1;32m   1260\u001b[0m                 blk.take_nd(\n\u001b[1;32m   1261\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m             new_blocks = [\n\u001b[0;32m-> 1260\u001b[0;31m                 blk.take_nd(\n\u001b[0m\u001b[1;32m   1261\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1288\u001b[0m             \u001b[0mallow_fill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m         new_values = algos.take_nd(\n\u001b[0m\u001b[1;32m   1291\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m         )\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m   1616\u001b[0m             \u001b[0;31m# check for promotion based on types only (do this first because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m             \u001b[0;31m# it's faster than computing a mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m                 \u001b[0;31m# check if promotion is actually required based on indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_promote\u001b[0;34m(dtype, fill_value)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m     \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_dtype_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36m_ensure_dtype_type\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alls = len(dfs_grayling)\n",
    "\n",
    "bad_dfs = []\n",
    "for df in dfs_grayling:\n",
    "    \n",
    "    if 'barbel' in df:\n",
    "        fish_number = df.split('/')[-1][5:19]\n",
    "        flow_cat = df.split('/')[-1][39:41]\n",
    "    if 'grayling' in df:\n",
    "        fish_number = df.split('/')[-1][5:21]\n",
    "        flow_cat = df.split('/')[-1][37:43]\n",
    "    if 'chub' in df:\n",
    "        fish_number = df.split('/')[-1][5:17]\n",
    "        flow_cat = df.split('/')[-1][33:39]\n",
    "        \n",
    "    print(alls, '++', fish_number, ' * ', flow_cat)\n",
    "    \n",
    "    try:\n",
    "        calc_max_gradient_direct(df, flow_cat, fish_number)\n",
    "        \n",
    "    except Exception as msg:\n",
    "        print(msg)\n",
    "        bad_dfs.append(df)\n",
    "        continue\n",
    "        #raise Exception\n",
    "    print('DONE WITH THIS ONE')\n",
    "        \n",
    "    alls -= 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/abbas/Documents/2020_03_03_SJE/2019_05_03_fish_dfs/desktop.ini'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abbas/Documents/2020_03_03_SJE/2019_05_03_fish_dfs/fish_2_barbel_46838_with_flow_data_cat_10_angles_and_max_gradients_with_behavior.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for df in df2[:1]:\n",
    "    print(df)\n",
    "    del (df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_number = df.split('/')[-1][5:19]\n",
    "flow_cat = df.split('/')[-1][35:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2_barbel_46838'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_cat\n",
    "fish_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
